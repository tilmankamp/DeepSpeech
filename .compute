#!/bin/bash

set -xe

apt-get install -y python3-venv sox libsox-fmt-all libopus0
python3 -m venv /tmp/venv
source /tmp/venv/bin/activate

pip install -U setuptools wheel pip
pip install -r <(grep -v tensorflow requirements.txt)
pip install tensorflow-gpu==1.14.0

# Install ds_ctcdecoder package from TaskCluster
pip install $(python3 util/taskcluster.py --decoder)

mkdir -p ../keep/summaries

data="${SHARED_DIR}/data"
fis="${data}/LDC/fisher"
swb="${data}/LDC/LDC97S62/swb"
lbs="${data}/OpenSLR/LibriSpeech/librivox"
cv="${data}/mozilla/CommonVoice/en_1087h_2019-06-12/clips"
npr="${data}/NPR/WAMU/sets/v0.3"
lima="${ML_GROUP_DIR}/libribot/en/export"

# --train_files "${fis}-train.csv","${swb}-train.csv","${lbs}-train-clean-100.csv","${lbs}-train-clean-360.csv","${lbs}-train-other-500.csv" \
# --feature_cache "${ML_GROUP_DIR}/ds/training/librimax-best-train.cache" \

python -u DeepSpeech.py \
  --train_files "${lima}/best-train.sdb" \
  --dev_files "${lbs}-dev-clean.csv" \
  --test_files "${lbs}-test-clean.csv" \
  --train_batch_size 24 \
  --dev_batch_size 48 \
  --test_batch_size 48 \
  --read_buffer "100MB" \
  --n_hidden 2048 \
  --learning_rate 0.0001 \
  --dropout_rate 0.4 \
  --lm_alpha 0.931289039105002 \
  --lm_beta 1.1834137581510284 \
  --epochs 10 \
  --train_cudnn \
  --noearly_stop \
  --checkpoint_dir "../keep" \
  --summary_dir "../keep/summaries"
